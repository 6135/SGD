{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W_HJjGDw5l1n"
   },
   "source": [
    "<h1>Tem Diabetes?</h1>\n",
    "  \n",
    "<h1>Class= Tem Diabetes</h1>  \n",
    "  \n",
    "<h2>Objectivo:</h2> \n",
    "\n",
    "\n",
    "Usando um conjunto de dados de Diabetes, prever se uma pessoa terá diabetes ou não usando caracteristicas medidas.\n",
    "\n",
    "<h2>Dados</h2>\n",
    "\n",
    "Número total de casos:768, 8 variáveis de entrada, uma variável de saída\n",
    "0= não tem diabetes : 500 \n",
    "1=tem diabetes : 268 \n",
    "\n",
    "Caracteristicas dos dados:\n",
    "\n",
    "O conjunto de dados contem apenas pacientes do sexo feminino (indios Pima), com 21 ou mais anos de idade\n",
    "\n",
    "Todos os atributos são numéricos\n",
    "\n",
    "Pode haver dados inválidos ou nulos\n",
    "\n",
    "atributos:\n",
    "\n",
    "pregnancies,\tGlucose,\tBloodPressure,\tSkinThickness,\tInsulin,\tBMI,\tDiabetesPedigreeFunction,\tAge,\t<b>Outcome</b>\n",
    "\n",
    "<b> Exemplos </b>\n",
    "\n",
    "6,148,72,35,0,33.6,0.627,50,1\n",
    "\n",
    "1,85,66,29,0,26.6,0.351,31,0\n",
    "\n",
    "<h2> Como funciona?</h2>\n",
    "  \n",
    "  1. Treina com 80% dos casos dados, escolhidos aleatoriamente\n",
    "  \n",
    "  2. Testa com os restantes 20% --> AVALIA (ESTATISTICAMENTE) SE O MODELO É CAPAZ DE DESCOBRIR NOVOS CASOS BEM\n",
    "  \n",
    "  3. Se o modelo for bom, posso usá-lo\n",
    "  \n",
    "  4. Dado um caso novo, medir as quantidades, formar um caso e submeter --> o sistema dá a sua previsão\n",
    "  \n",
    "  caso novo: 3,154,71,55,0,31.6,0.638,40,<b>?</b>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DIIbQIM05l1p"
   },
   "source": [
    "NOTA: vamos correr mocalmente, mas SE QUISER CORRER EM COLAB, TERÁ DE TER O SEGUINTE:\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#dataset = pd.read_csv('pima-indians-diabetes.data.csv')\n",
    "\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "import io\n",
    "dataset = pd.read_csv(io.BytesIO(uploaded['pima-indians-diabetes.data.csv']))\n",
    "# Dataset is now stored in a Pandas Dataframe\n",
    "\n",
    "dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "dataset = pd.read_csv('pima-indians-diabetes.data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "plHQGXUX5l1t"
   },
   "outputs": [],
   "source": [
    "dataset.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7algBLpD5l1x"
   },
   "source": [
    "<h2> P1. Which two attributes have top correlation with class?</h2>\n",
    "\n",
    "<h2>P2. what two attributes have top correlation between them?</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DgnL1ZE05l1y"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "plt.rcParams['font.size'] = '16'\n",
    "sns.heatmap(dataset.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wDrpQ4rh5l17"
   },
   "source": [
    "<h2>P3. What does the next code do?</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wBZDFbhG5l18"
   },
   "outputs": [],
   "source": [
    "#standardizing the input feature\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KO5D_llE-fQR"
   },
   "source": [
    "<h2>P4. WHat does the next code do? how big are train and test data?</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OKjAoQ-q5l2A"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0p3iGveP5l2D"
   },
   "source": [
    "<h2>O que faremos de seguida</h2>\n",
    "Pré-processámos os dados e agora estamos prontos para construir a rede neuronal.\n",
    "\n",
    "Estamos a usar keras para construir a rede neuronal. Importamos a biblioteca keras para criar as camadas de rede neuronal.\n",
    "\n",
    "Existem dois tipos principais de modelos disponíveis no keras - \"Sequential\" e \"Model\". usaremos o modelo \"sequential\" para construir nossa rede neuronal.\n",
    "\n",
    "Utilizamos a biblioteca \"Dense\" para criar camadas de entrada, oculta e saída de uma rede neuronal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OE7TuIBx5l2E"
   },
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_DnREKQ4fmDA"
   },
   "source": [
    "<h2>P5. Olhando para a figura da rede neuronal construida, preencha o que falta nos pontos seguintes </h2>\n",
    "\n",
    "<h3>(a) Temos ________ variáveis e uma variável objectivo (diabetes ou não).\n",
    "\n",
    "Teremos _______ camadas escondidas (hidden).\n",
    "\n",
    "Cada camada escondida terá ________ nós.\n",
    "\n",
    "Temos uma função de activação dos neuronios das camadas escondidas ReLu, a qual usará a função de activação sigmoide.\n",
    "\n",
    "Nota: uma camada \"Dense\" implementa a função: output = activation(dot(input, kernel) + bias)\", sendo que dot é o ____________________ e o kernel são _________________</h3>\n",
    "\n",
    "Keras oferece multiplos initializadores possiveis para o kernel (pesos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E0lcrg-_a47p"
   },
   "source": [
    "![alt text](https://drive.google.com/uc?id=1pYrjXoRBOTkIeiBD7RXuzogqNO0bWnqK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yA0NvPt05l2J"
   },
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "#First Hidden Layer\n",
    "classifier.add(Dense(4, activation='relu', input_dim=8))\n",
    "#Second  Hidden Layer\n",
    "classifier.add(Dense(4, activation='relu'))\n",
    "#Output Layer\n",
    "classifier.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7wcAmJ7f5l2M"
   },
   "source": [
    "Uma vez criadas as diferentes camadas, compilamos agora a rede neuronal.\n",
    "\n",
    "Como este é um problema de classificação binária, usamos binary_crossentropy para calcular a função de perda entre a saída real e a saída prevista.\n",
    "\n",
    "Para otimizar nossa rede neuronal, usamos Adam. Adam significa estimativa adaptativa do momento. Adam é uma combinação de RMSProp + Momentum.\n",
    "\n",
    "O momento leva em consideração os gradientes passados para suavizar a descida do gradiente.\n",
    "\n",
    "usamos métricas para medir o desempenho do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3qjgpNQy5l2N"
   },
   "outputs": [],
   "source": [
    "#Compiling the neural network\n",
    "import tensorflow as tf\n",
    "classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1YvL0FYq5l2Q"
   },
   "source": [
    "agora ajustamos os dados de treino ao modelo que criámos. usamos um batch_size de 10. Isso implica que usamos 10 amostras por atualização de gradiente.\n",
    "\n",
    "Iteramos mais de 100 épocas para treinar o modelo. Uma época é uma iteração em todo o conjunto de dados.\n",
    "\n",
    "<h2> P6. what's the \"loss\"? what do we want loss to be? what about \"accuracy\", \"precision\" and \"recall\"? is this a good result?</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g4qvycU65l2R"
   },
   "outputs": [],
   "source": [
    "#Fitting the data to the training dataset\n",
    "classifier.fit(X_train,y_train, batch_size=10, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ySOzWba5l2V"
   },
   "source": [
    "<h2>P8. Is the comparison of results train/test the one you would expect? why?</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MM5SBYS15l2W"
   },
   "outputs": [],
   "source": [
    "eval_model=classifier.evaluate(X_train, y_train)\n",
    "eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-rhAMoA65l2Z"
   },
   "outputs": [],
   "source": [
    "eval_model=classifier.evaluate(X_test, y_test)\n",
    "eval_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NhcEkBlB5l2c"
   },
   "source": [
    "## Tell us if the first 5 estimations are correct? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rzp1k3F35l2d"
   },
   "outputs": [],
   "source": [
    "y1_pred=classifier.predict(X_test)\n",
    "y_pred =(y1_pred>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KJ-6Yz3-5l2g"
   },
   "outputs": [],
   "source": [
    "y1_test = pd.DataFrame(y_test.values)\n",
    "np.stack((y1_test.values,y1_pred),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y0l3jqAzMNwm"
   },
   "source": [
    "<h2> P11. What does the next matrix tell us?</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RPrJxi2E5l2m",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IAAqNIxy5l2H"
   },
   "source": [
    "<h1>Algumas respostas</h1>\n",
    "Temos 8 variáveis e uma variável objectivo (diabetes ou não). \n",
    "\n",
    "Teremos duas camadas escondidas (hidden). \n",
    "\n",
    "Cada camada escondida terá 4 nós.\n",
    "\n",
    "Temos uma função de activação dos neuronios das camadas escondidas ReLu, a qual usará a função de activação sigmoide\n",
    "\n",
    "\"Dense layer implements output = activation(dot(input, kernel) + bias)\"\n",
    "\n",
    "\n",
    "Keras oferece multiplos initializadores possiveis\n",
    "\n",
    "Nota: uma camada \"Dense\" implementa a função: output = activation(dot(input, kernel) + bias)\", sendo que dot é o produto e o kernel são pesos\n",
    "\n",
    "Keras oferece multiplos initializadores possiveis para o kernel (pesos)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of ClassificaçãoUsandoRedesNeuronais.ipynb",
   "provenance": [
    {
     "file_id": "1or0ujQNr9dBbEDXQDvK_ZKAwi7x9RwM3",
     "timestamp": 1570871216097
    },
    {
     "file_id": "1BtpJ49cyag4ax4barxlOa-OWssQXTHNc",
     "timestamp": 1570871000545
    },
    {
     "file_id": "1nkJlxd9Sch8S4rqyouRZB8IF3vZ7PORo",
     "timestamp": 1570781986108
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
